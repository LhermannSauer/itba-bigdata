{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f4e7295-6c9d-426d-8b0f-108730bb0632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# <-- replace with your silver dataset path\n",
    "SILVER_PATH = \"/Volumes/workspace/sentiment_analysis/silver\"\n",
    "GOLD_OUT_PATH = \"/Volumes/workspace/sentiment_analysis/gold\"\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"review_id\", \"product_id\", \"customer_id\",\n",
    "    \"star_rating\", \"review_date\", \"review_body\"\n",
    "]\n",
    "\n",
    "SENTIMENT_MAP = {\n",
    "    \"negative\": [1, 2],\n",
    "    \"neutral\": [3],\n",
    "    \"positive\": [4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30c8c9af-90d1-4e83-ad89-23fe2c0767e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(SILVER_PATH)\n",
    "print(\n",
    "    f\"Loaded Silver dataset with {df.count()} rows and {len(df.columns)} columns.\")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "801ff9da-7ce8-46e5-b631-5473fe1127d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "missing = [c for c in REQUIRED_FIELDS if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required fields: {missing}\")\n",
    "\n",
    "# Filter invalid or incomplete rows\n",
    "df = df.filter(\n",
    "    F.col(\"review_body\").isNotNull() &\n",
    "    (F.length(F.trim(F.col(\"review_body\"))) > 5) &\n",
    "    (F.col(\"star_rating\").isNotNull())\n",
    ")\n",
    "df = df.withColumn(\"star_rating\", F.col(\"star_rating\").cast(T.IntegerType()))\n",
    "df = df.filter(F.col(\"star_rating\").between(1, 5))\n",
    "\n",
    "print(f\"After filtering: {df.count()} rows remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3c6e204-9aea-4d64-8dc5-5b0c45e0d83d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def basic_text_cleaning(df, text_col=\"review_body\", out_col=\"clean_text\"):\n",
    "    expr = F.col(text_col)\n",
    "    expr = F.lower(F.regexp_replace(expr, r\"\\s+\", \" \"))\n",
    "    expr = F.regexp_replace(expr, r\"<[^>]+>\", '')\n",
    "    expr = F.regexp_replace(expr, r\"[“”«»„‟]\", '\"')\n",
    "    df = df.withColumn(out_col, expr)\n",
    "    df = df.withColumn(\"n_chars\", F.length(F.col(out_col)))\n",
    "    df = df.withColumn(\"n_words\", F.size(F.split(F.col(out_col), \" \")))\n",
    "    return df\n",
    "\n",
    "\n",
    "df = basic_text_cleaning(df)\n",
    "\n",
    "df.select(\"clean_text\", \"n_words\").show(5, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c38e7db5-b784-474b-a110-f1b9712c903e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def map_ratings_to_labels(df, rating_col=\"star_rating\", out_col=\"sentiment_label\"):\n",
    "    mapping = SENTIMENT_MAP\n",
    "    expr = F.when(F.col(rating_col).isin(mapping[\"negative\"]), F.lit(\"negative\")) \\\n",
    "        .when(F.col(rating_col).isin(mapping[\"neutral\"]), F.lit(\"neutral\")) \\\n",
    "        .when(F.col(rating_col).isin(mapping[\"positive\"]), F.lit(\"positive\")) \\\n",
    "        .otherwise(F.lit(\"neutral\"))\n",
    "    return df.withColumn(out_col, expr)\n",
    "\n",
    "\n",
    "df = map_ratings_to_labels(df)\n",
    "\n",
    "# Quick check\n",
    "df.groupBy(\"sentiment_label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45c2ba43-c9bb-4bb2-9429-8ed8f0afa09e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "product_window = Window.partitionBy(\n",
    "    \"product_id\").orderBy(F.col(\"review_date\").desc())\n",
    "user_window = Window.partitionBy(\"user_id\").orderBy(\"review_date\")\n",
    "\n",
    "df = df.withColumn(\"review_rank\", F.rank().over(product_window))\n",
    "df = df.withColumn(\"avg_sentiment_product\", F.avg(\n",
    "    \"sentiment_label\").over(product_window.rowsBetween(-5, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf2e357a-4bc7-4822-b743-db0a2a48dc54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "selected_cols = [\n",
    "    \"review_id\", \"product_id\", \"customer_id\",\n",
    "    \"clean_text\", \"sentiment_label\", \"star_rating\",\n",
    "    \"review_date\", \"helpful_votes\", \"total_votes\", \"verified_purchase\"\n",
    "]\n",
    "selected_cols = [c for c in selected_cols if c in df.columns]\n",
    "\n",
    "df_gold = df.select(*selected_cols)\n",
    "\n",
    "df_gold.show(5, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bfe44c6-9744-40e1-ad42-5c0c96708ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_gold.write.mode(\"overwrite\").parquet(GOLD_OUT_PATH)\n",
    "\n",
    "# Metadata\n",
    "created_at = df_gold.select(F.current_timestamp().alias(\n",
    "    \"created_at\")).first()[\"created_at\"]\n",
    "\n",
    "meta = {\n",
    "    # convert to string if you plan to JSON dump\n",
    "    \"created_at\": str(created_at),\n",
    "    \"total_rows\": df_gold.count(),\n",
    "    \"label_distribution\": {\n",
    "        r[\"sentiment_label\"]: r[\"count\"]\n",
    "        for r in df_gold.groupBy(\"sentiment_label\").count().collect()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Gold sentiment dataset saved to {GOLD_OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb523ce-761d-4fd4-982d-3a6c9c1f8e25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"total_rows\", df_gold.count())\n",
    "    mlflow.log_param(\"n_columns\", len(df_gold.columns))\n",
    "    mlflow.log_param(\"columns\", \", \".join(df_gold.columns))\n",
    "    # Label distribution\n",
    "    label_dist = df_gold.groupBy(\"sentiment_label\").count().collect()\n",
    "    total = sum([r[\"count\"] for r in label_dist])\n",
    "\n",
    "    for r in label_dist:\n",
    "        label = r[\"sentiment_label\"]\n",
    "        ratio = r[\"count\"] / total\n",
    "        mlflow.log_metric(f\"label_ratio_{label}\", ratio)\n",
    "\n",
    "    # Average review length\n",
    "    from pyspark.sql import functions as F\n",
    "    avg_length = df_gold.select(F.avg(F.length(\"clean_text\"))).first()[0]\n",
    "    mlflow.log_metric(\"avg_review_length\", float(avg_length))\n",
    "\n",
    "    # Missing data ratio (quick data health check)\n",
    "    missing_ratios = {\n",
    "        col: df_gold.filter(F.col(col).isNull()).count() / total\n",
    "        for col in df_gold.columns\n",
    "    }\n",
    "    for col, ratio in missing_ratios.items():\n",
    "        mlflow.log_metric(f\"missing_ratio_{col}\", ratio)\n",
    "\n",
    "    completeness_score = 1 - \\\n",
    "        sum(missing_ratios.values()) / len(df_gold.columns)\n",
    "    balance_score = 1 - \\\n",
    "        max(abs(r[\"count\"] - total / len(label_dist)) /\n",
    "            total for r in label_dist)\n",
    "\n",
    "    mlflow.log_dict(\"metadata\", json.dumps(meta))\n",
    "    mlflow.log_metric(\"completeness_score\", completeness_score)\n",
    "    mlflow.log_metric(\"balance_score\", balance_score)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_data_ingestion_sa",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
